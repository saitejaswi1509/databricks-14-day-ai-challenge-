{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "219e1007-ebd4-4868-acf0-14bfd8ddded1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### \uD83D\uDCD8 Day 12 | MLflow Basics  \n",
    "### Databricks 14-Day AI Challenge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a721faf-1b1a-4de9-85e2-f3da8211d884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### \uD83C\uDFAF Objective\n",
    "Understand how to track machine learning experiments using MLflow by logging parameters, metrics, models, and comparing multiple runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e90e84a-a1a7-4ee7-9eeb-624231d3117c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering & Data Preparation\n",
    "Preparing features and target variable for regression modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "618e2ee5-a08c-42bb-b8fd-6b44e5b0e4e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Purchase_Amount</th><th>Age</th><th>day_of_week</th><th>month</th></tr></thead><tbody><tr><td>780.69</td><td>63</td><td>6</td><td>4</td></tr><tr><td>738.56</td><td>59</td><td>1</td><td>7</td></tr><tr><td>178.34</td><td>26</td><td>1</td><td>9</td></tr><tr><td>401.09</td><td>43</td><td>4</td><td>6</td></tr><tr><td>594.83</td><td>48</td><td>3</td><td>10</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         780.69,
         63,
         6,
         4
        ],
        [
         738.56,
         59,
         1,
         7
        ],
        [
         178.34,
         26,
         1,
         9
        ],
        [
         401.09,
         43,
         4,
         6
        ],
        [
         594.83,
         48,
         3,
         10
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Purchase_Amount",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "day_of_week",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "month",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 50000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.table(\"default.ecommerce_transactions\")\n",
    "\n",
    "df_ml = (\n",
    "    df.select(\n",
    "        \"Purchase_Amount\",\n",
    "        \"Age\",\n",
    "        F.dayofweek(\"Transaction_Date\").alias(\"day_of_week\"),\n",
    "        F.month(\"Transaction_Date\").alias(\"month\")\n",
    "    )\n",
    "    .na.drop()\n",
    "    .filter(F.col(\"Purchase_Amount\").isNotNull())\n",
    ")\n",
    "\n",
    "display(df_ml.limit(5))\n",
    "print(\"Rows:\", df_ml.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5645cde2-17f4-48e8-a851-8c5b0e5cbe02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train-Test Split\n",
    "Splitting data into training and testing sets for model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcd0052f-f4b1-4f14-b17e-a6b49b721e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (40000, 3)\nTest shape : (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to pandas\n",
    "pdf = df_ml.toPandas()\n",
    "\n",
    "# Features & target\n",
    "X = pdf[[\"Age\", \"day_of_week\", \"month\"]]\n",
    "y = pdf[\"Purchase_Amount\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72525eed-385c-44f1-a7fd-a730cd75418b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MLflow Experiment Setup\n",
    "Creating and setting an MLflow experiment to track all model runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f84f5cb-8a45-43c5-840f-01417dacc89f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment set\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Setting experiment\n",
    "mlflow.set_experiment(\"/Users/\" + spark.sql(\"select current_user()\").first()[0] + \"/DAY_12_MLflow_Regression\")\n",
    "\n",
    "print(\"Experiment set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3556782-9fbc-45f9-b9a4-11fbd079cfbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Training Run 1 (Baseline Regression)\n",
    "Training a simple Linear Regression model and logging parameters, metrics, and model artifacts using MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7192f8a3-1c65-4555-ab4a-7e41693fcdef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run completed | R2 Score: -0.0006\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# cast to float to avoid MLflow integer-missing warning\n",
    "X_train = X_train.astype(\"float64\")\n",
    "X_test  = X_test.astype(\"float64\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"linear_regression_v1\"):\n",
    "    mlflow.log_param(\"model\", \"LinearRegression\")\n",
    "    mlflow.log_param(\"features\", \"Age,day_of_week,month\")\n",
    "\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    r2 = lr.score(X_test, y_test)\n",
    "    mlflow.log_metric(\"r2_score\", r2)\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, \"model\", input_example=X_train.head(5))\n",
    "\n",
    "print(f\"Run completed | R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2136d8d0-436a-450e-9f81-e91f9be1e326",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Enhancement\n",
    "Adding an additional feature to test its impact on model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e427d55-439e-4321-bb54-487211a8d56e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split: (40000, 4) (10000, 4)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df2 = (\n",
    "    spark.table(\"default.ecommerce_transactions\")\n",
    "    .select(\n",
    "        \"Purchase_Amount\",\n",
    "        \"Age\",\n",
    "        F.dayofweek(\"Transaction_Date\").alias(\"day_of_week\"),\n",
    "        F.month(\"Transaction_Date\").alias(\"month\"),\n",
    "        F.when(F.dayofweek(\"Transaction_Date\").isin([1,7]), 1).otherwise(0).alias(\"is_weekend\")\n",
    "    )\n",
    "    .na.drop()\n",
    ")\n",
    "\n",
    "pdf2 = df2.toPandas()\n",
    "\n",
    "X2 = pdf2[[\"Age\", \"day_of_week\", \"month\", \"is_weekend\"]]\n",
    "y2 = pdf2[\"Purchase_Amount\"]\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train-test split:\", X2_train.shape, X2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f771fa4b-9559-4e99-92d5-79ac6fa68595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Model Training Run 2 (Enhanced Features)\n",
    "Training a second regression model with an updated feature set and logging it as a new MLflow run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "276098d9-37d4-4f47-bbf5-75aa24397d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2 completed | R2 Score: -0.0009\n"
     ]
    }
   ],
   "source": [
    "mlflow.start_run(run_name=\"linear_regression_v2_weekend\"):\n",
    "    lr2 = LinearRegression().fit(X2_train, y2_train)\n",
    "    r2_v2 = lr2.score(X2_test, y2_test)\n",
    "    mlflow.log_metric(\"r2_score\", r2_v2)\n",
    "\n",
    "    mlflow.sklearn.log_model(lr2, \"model\", input_example=X2_train.head(5))\n",
    "\n",
    "print(f\"Run 2 completed | R2 Score: {r2_v2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day12_MLFlowbasics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}